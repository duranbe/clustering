{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification using  Naive Bayes\n",
    "### Based on IMDB dataset\n",
    "\n",
    "Source Annexe : https://web.stanford.edu/~jurafsky/slp3/slides/7_NB.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list=glob.glob(pathname=\"./data/movie-reviews-en/train/pos/*.txt\")\n",
    "neg_list=glob.glob(pathname=\"./data/movie-reviews-en/train/neg/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_word = 10000    #Nb of words to keep in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get all text files as a list of string\n",
    "def get_text_list(file_list):\n",
    "    text_list = []\n",
    "    \n",
    "    for file in file_list:\n",
    "        \n",
    "        with open(file,'r') as f:\n",
    "            text_list.append(f.read())\n",
    "            \n",
    "    return(text_list)\n",
    "        \n",
    "pos_text = ' '.join(get_text_list(pos_list))\n",
    "neg_text = ' '.join(get_text_list(neg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small Preprocessing\n",
    "\n",
    "Remove punctuation and line escape char '\\n'\n",
    "\n",
    "Then we only keep the n_word most occuring word across all text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_text = pos_text.translate(str.maketrans('','', string.punctuation))\n",
    "pos_text = pos_text.replace('\\n','')\n",
    "pos_count = dict(Counter(pos_text.split()).most_common(n_word))\n",
    "\n",
    "neg_text = neg_text.translate(str.maketrans('','', string.punctuation))\n",
    "neg_text = neg_text.replace('\\n','')\n",
    "neg_count = dict(Counter(neg_text.split()).most_common(n_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilty functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return the probabilty to have the input word knowing the class\n",
    "#P(wi|Cj)\n",
    "#P('nice'|Positive)\n",
    "# With Laplace Smoothing\n",
    "\n",
    "def proba_word(word,counter):    \n",
    "    \n",
    "    try: \n",
    "        \n",
    "        # If the word is in our Vocabulary\n",
    "        r = (counter[word]+1)/(sum(counter.values())+len(counter))\n",
    "        \n",
    "    except KeyError:\n",
    "        # Else counter[word] = 0 \n",
    "        r = (1)/(sum(counter.values())+len(counter))\n",
    "        \n",
    "    return(np.float64(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the sum of the log probabilities of each word in the input text\n",
    "\n",
    "def proba_text(text,counter):   \n",
    "    \n",
    "    probs=[]\n",
    "    \n",
    "    for word in list(set(text.split())):\n",
    "        probs.append(np.log(proba_word(word,counter)))\n",
    "        \n",
    "    return(np.sum(probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NBmodel(text_array,counter):\n",
    "    \n",
    "    predictions = []\n",
    "    neg_count,pos_count = counter\n",
    "    \n",
    "    for text in text_array:\n",
    "        \n",
    "        probs = [proba_text(text,neg_count),proba_text(text,pos_count)]\n",
    "        predictions.append(np.argmax(probs))\n",
    "        \n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_test_list = glob.glob(pathname=\"./data/movie-reviews-en/test/pos/*.txt\")\n",
    "neg_test_list = glob.glob(pathname=\"./data/movie-reviews-en/test/neg/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_test_text = get_text_list(pos_test_list)      \n",
    "neg_test_text = get_text_list(neg_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(pos_test_text)):\n",
    "    pos_test_text[i] = pos_test_text[i].translate(str.maketrans('','', string.punctuation))\n",
    "    pos_test_text[i] = pos_test_text[i].replace('\\n','')\n",
    "\n",
    "for i in range(0,len(neg_test_text)):\n",
    "    neg_test_text[i] = neg_test_text[i].translate(str.maketrans('','', string.punctuation))\n",
    "    neg_test_text[i] = neg_test_text[i].replace('\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_results = NBmodel(pos_test_text,[neg_count,pos_count])\n",
    "neg_results = NBmodel(neg_test_text,[neg_count,pos_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Negative Accuracy : 0.95 '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\" Negative Accuracy : {(len(neg_results)-np.sum(neg_results))/(len(neg_results))} \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive Accuracy : 0.7'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Positive Accuracy : {np.sum(pos_results)/(len(pos_results))}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70, 30],\n",
       "       [ 5, 95]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP = np.sum(pos_results)\n",
    "TN = len(neg_results)-np.sum(neg_results)\n",
    "FP = len(pos_results)-np.sum(pos_results)\n",
    "FN = np.sum(neg_results)\n",
    "\n",
    "z = np.array([[TP,FP],[FN,TN]])\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Global Accuracy : 0.825'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Global Accuracy : {(TP+TN)/(TP+TN+FP+FN)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now with a bit of Preprocessing\n",
    "\n",
    "Removing stop words using ntlk package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re \n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "for word in stopwords:\n",
    "    pos_text = re.sub(' '+ word+' ',' ',pos_text)\n",
    "    neg_text = re.sub(' '+ word+' ',' ',neg_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_count = dict(Counter(pos_text.split()).most_common(n_word))\n",
    "neg_count = dict(Counter(neg_text.split()).most_common(n_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in stopwords:\n",
    "    for i in range(0,len(pos_test_text)):\n",
    "        pos_test_text[i] = re.sub(' '+ word+' ',' ',pos_test_text[i])\n",
    "        neg_test_text[i] = re.sub(' '+ word+' ',' ',neg_test_text[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative Accuracy : 0.91'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_results = NBmodel(neg_test_text,[neg_count,pos_count])\n",
    "f\"Negative Accuracy : {(len(neg_results)-np.sum(neg_results))/(len(neg_results))}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive Accuracy : 0.72'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_results = NBmodel(pos_test_text,[neg_count,pos_count])\n",
    "f\"Positive Accuracy : {np.sum(pos_results)/(len(pos_results))}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[72, 28],\n",
       "       [ 9, 91]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP = np.sum(pos_results)\n",
    "TN = len(neg_results)-np.sum(neg_results)\n",
    "FP = len(pos_results)-np.sum(pos_results)\n",
    "FN = np.sum(neg_results)\n",
    "\n",
    "z = np.array([[TP,FP],[FN,TN]])\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Global Accuracy : 0.815'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Global Accuracy : {(TP+TN)/(TP+TN+FP+FN)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Stemmer\n",
    "\n",
    "Testing nltk english stemmer\n",
    "\n",
    "Restart from scratch because we have removed stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "pos_list=glob.glob(pathname=\"./data/movie-reviews-en/train/pos/*.txt\")\n",
    "neg_list=glob.glob(pathname=\"./data/movie-reviews-en/train/neg/*.txt\")\n",
    "\n",
    "pos_text = ' '.join(get_text_list(pos_list))\n",
    "neg_text = ' '.join(get_text_list(neg_list))\n",
    "\n",
    "pos_text = pos_text.translate(str.maketrans('','', string.punctuation))\n",
    "pos_text = pos_text.replace('\\n','')\n",
    "\n",
    "neg_text = neg_text.translate(str.maketrans('','', string.punctuation))\n",
    "neg_text = neg_text.replace('\\n','')\n",
    "\n",
    "stem_pos_text = []\n",
    "stem_neg_text = []\n",
    "EnglishSnowballStemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "for w in pos_text.split():\n",
    "    \n",
    "    if w != ' ':\n",
    "        stemword = EnglishSnowballStemmer.stem(w)\n",
    "        stem_pos_text.append(stemword)\n",
    "        \n",
    "for w in neg_text.split():\n",
    "    \n",
    "    if w != ' ':\n",
    "        stemword = EnglishSnowballStemmer.stem(w)\n",
    "        stem_neg_text.append(stemword)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_pos_count = dict(Counter(stem_pos_text).most_common(n_word))\n",
    "stem_neg_count = dict(Counter(stem_neg_text).most_common(n_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_test_list = glob.glob(pathname=\"./data/movie-reviews-en/test/pos/*.txt\")\n",
    "neg_test_list = glob.glob(pathname=\"./data/movie-reviews-en/test/neg/*.txt\")\n",
    "\n",
    "pos_test_text = get_text_list(pos_test_list)      \n",
    "neg_test_text = get_text_list(neg_test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the english snowball stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(pos_test_text)):\n",
    "    pos_test_text[i] = pos_test_text[i].translate(str.maketrans('','', string.punctuation))\n",
    "    pos_test_text[i] = pos_test_text[i].replace('\\n','')\n",
    "    pos_test_text[i] = ' '.join(EnglishSnowballStemmer.stem(w) for w in pos_test_text[i].split())\n",
    "\n",
    "for i in range(0,len(neg_test_text)):\n",
    "    neg_test_text[i] = neg_test_text[i].translate(str.maketrans('','', string.punctuation))\n",
    "    neg_test_text[i] = neg_test_text[i].replace('\\n','')\n",
    "    neg_test_text[i] = ' '.join(EnglishSnowballStemmer.stem(w) for w in neg_test_text[i].split())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Accuracy : 0.92\n",
      "Positive Accuracy : 0.73\n"
     ]
    }
   ],
   "source": [
    "pos_results = NBmodel(pos_test_text,[stem_neg_count,stem_pos_count])\n",
    "neg_results = NBmodel(neg_test_text,[stem_neg_count,stem_pos_count])\n",
    "\n",
    "print(f\"Negative Accuracy : {(len(neg_results)-np.sum(neg_results))/(len(neg_results))}\")\n",
    "print(f\"Positive Accuracy : {np.sum(pos_results)/(len(pos_results))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[73, 27],\n",
       "       [ 8, 92]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP = np.sum(pos_results)\n",
    "TN = len(neg_results)-np.sum(neg_results)\n",
    "FP = len(pos_results)-np.sum(pos_results)\n",
    "FN = np.sum(neg_results)\n",
    "\n",
    "z = np.array([[TP,FP],[FN,TN]])\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Global Accuracy : 0.825'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Global Accuracy : {(TP+TN)/(TP+TN+FP+FN)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "pos_list=glob.glob(pathname=\"./data/movie-reviews-en/train/pos/*.txt\")\n",
    "neg_list=glob.glob(pathname=\"./data/movie-reviews-en/train/neg/*.txt\")\n",
    "\n",
    "pos_text = ' '.join(get_text_list(pos_list))\n",
    "neg_text = ' '.join(get_text_list(neg_list))\n",
    "\n",
    "pos_text = pos_text.translate(str.maketrans('','', string.punctuation))\n",
    "pos_text = pos_text.replace('\\n','')\n",
    "\n",
    "neg_text = neg_text.translate(str.maketrans('','', string.punctuation))\n",
    "neg_text = neg_text.replace('\\n','')\n",
    "\n",
    "lemm_pos_text = []\n",
    "lemm_neg_text = []\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for w in pos_text.split():\n",
    "    \n",
    "    if w != ' ':\n",
    "        lemmword = wordnet_lemmatizer.lemmatize(w)\n",
    "        lemm_pos_text.append(lemmword)\n",
    "        \n",
    "for w in neg_text.split():\n",
    "    \n",
    "    if w != ' ':\n",
    "        lemmword = wordnet_lemmatizer.lemmatize(w)\n",
    "        lemm_neg_text.append(lemmword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_pos_count = dict(Counter(lemm_pos_text).most_common(n_word))\n",
    "lemm_neg_count = dict(Counter(lemm_neg_text).most_common(n_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_test_list = glob.glob(pathname=\"./data/movie-reviews-en/test/pos/*.txt\")\n",
    "neg_test_list = glob.glob(pathname=\"./data/movie-reviews-en/test/neg/*.txt\")\n",
    "\n",
    "pos_test_text = get_text_list(pos_test_list)      \n",
    "neg_test_text = get_text_list(neg_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(pos_test_text)):\n",
    "    pos_test_text[i] = pos_test_text[i].translate(str.maketrans('','', string.punctuation))\n",
    "    pos_test_text[i] = pos_test_text[i].replace('\\n','')\n",
    "    pos_test_text[i] = ' '.join(wordnet_lemmatizer.lemmatize(w) for w in pos_test_text[i].split())\n",
    "\n",
    "for i in range(0,len(neg_test_text)):\n",
    "    neg_test_text[i] = neg_test_text[i].translate(str.maketrans('','', string.punctuation))\n",
    "    neg_test_text[i] = neg_test_text[i].replace('\\n','')\n",
    "    neg_test_text[i] = ' '.join(wordnet_lemmatizer.lemmatize(w) for w in neg_test_text[i].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Accuracy : 0.94\n",
      "Positive Accuracy : 0.73\n"
     ]
    }
   ],
   "source": [
    "pos_results = NBmodel(pos_test_text,[lemm_neg_count,lemm_pos_count])\n",
    "neg_results = NBmodel(neg_test_text,[lemm_neg_count,lemm_pos_count])\n",
    "\n",
    "print(f\"Negative Accuracy : {(len(neg_results)-np.sum(neg_results))/(len(neg_results))}\")\n",
    "print(f\"Positive Accuracy : {np.sum(pos_results)/(len(pos_results))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[73, 27],\n",
       "       [ 6, 94]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP = np.sum(pos_results)\n",
    "TN = len(neg_results)-np.sum(neg_results)\n",
    "FP = len(pos_results)-np.sum(pos_results)\n",
    "FN = np.sum(neg_results)\n",
    "\n",
    "z = np.array([[TP,FP],[FN,TN]])\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Global Accuracy : 0.835'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Global Accuracy : {(TP+TN)/(TP+TN+FP+FN)}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
